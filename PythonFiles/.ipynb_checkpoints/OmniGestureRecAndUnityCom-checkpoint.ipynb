{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library version: 2.4.0.144\n",
      "Number of cameras detected: 1\n",
      "Running example for camera 0...\n",
      "*** DEVICE INFORMATION ***\n",
      "\n",
      "DeviceID: USB\\VID_1E10&PID_3300&MI_00\\6&56CCD35&0&0000\n",
      "DeviceSerialNumber: 20304031\n",
      "DeviceVendorName: Point Grey Research\n",
      "DeviceModelName: Grasshopper3 GS3-U3-41C6C\n",
      "DeviceType: USB3Vision\n",
      "DeviceDisplayName: Point Grey Research Grasshopper3 GS3-U3-41C6C\n",
      "DeviceAccessStatus: OpenReadWrite\n",
      "DeviceVersion: FW:v2.23.3.02 FPGA:v2.02\n",
      "DeviceDriverVersion: PGRUSBCam.sys : 2.7.3.235\n",
      "DeviceUserID: \n",
      "DeviceIsUpdater: 0\n",
      "DeviceInstanceId: USB\\VID_1E10&PID_3300&MI_00\\6&56CCD35&0&0000\n",
      "DeviceLocation: 0000.0014.0000.017.000.000.000.000.000\n",
      "DeviceCurrentSpeed: SuperSpeed\n",
      "GUIXMLLocation: Device\n",
      "GUIXMLPath: Input.xml\n",
      "GenICamXMLLocation: Device\n",
      "GenICamXMLPath: \n",
      "DeviceU3VProtocol: 1\n",
      "DevicePortId: 17\n",
      "*** IMAGE ACQUISITION ***\n",
      "\n",
      "Acquisition mode set to continuous...\n",
      "Acquiring images...\n",
      "Device serial number retrieved as 20304031...\n"
     ]
    }
   ],
   "source": [
    "## this is the combination of spinaker,mediapipe, recognition and unity communication so far\n",
    "\n",
    "\n",
    "### With gesture recognition\n",
    "\n",
    "\n",
    "\n",
    "# Spinnaker SDK\n",
    "import os\n",
    "from pyspin import PySpin as spin\n",
    "import sys\n",
    "\n",
    "# Mediapipe hand tracking and OpenCV and Pillow\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# gesture recognition\n",
    "from utils import CvFpsCalc\n",
    "from model import KeyPointClassifier\n",
    "from model import PointHistoryClassifier\n",
    "\n",
    "import csv\n",
    "import copy\n",
    "import argparse\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "\n",
    "# Unity python communication\n",
    "import time\n",
    "import zmq\n",
    "import random\n",
    "\n",
    "context = zmq.Context()\n",
    "socket = context.socket(zmq.REP)\n",
    "socket.bind(\"tcp://*:5555\")\n",
    "unity_output = \"-1\"\n",
    "\n",
    "\n",
    "\n",
    "# coding=utf-8\n",
    "# =============================================================================\n",
    "# Copyright (c) 2001-2021 FLIR Systems, Inc. All Rights Reserved.\n",
    "#\n",
    "# This software is the confidential and proprietary information of FLIR\n",
    "# Integrated Imaging Solutions, Inc. (\"Confidential Information\"). You\n",
    "# shall not disclose such Confidential Information and shall use it only in\n",
    "# accordance with the terms of the license agreement you entered into\n",
    "# with FLIR Integrated Imaging Solutions, Inc. (FLIR).\n",
    "#\n",
    "# FLIR MAKES NO REPRESENTATIONS OR WARRANTIES ABOUT THE SUITABILITY OF THE\n",
    "# SOFTWARE, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "# IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR\n",
    "# PURPOSE, OR NON-INFRINGEMENT. FLIR SHALL NOT BE LIABLE FOR ANY DAMAGES\n",
    "# SUFFERED BY LICENSEE AS A RESULT OF USING, MODIFYING OR DISTRIBUTING\n",
    "# THIS SOFTWARE OR ITS DERIVATIVES.\n",
    "# =============================================================================\n",
    "#\n",
    "# Acquisition.py shows how to acquire images. It relies on\n",
    "# information provided in the Enumeration example. Also, check out the\n",
    "# ExceptionHandling and NodeMapInfo examples if you haven't already.\n",
    "# ExceptionHandling shows the handling of standard and Spinnaker exceptions\n",
    "# while NodeMapInfo explores retrieving information from various node types.\n",
    "#\n",
    "# This example touches on the preparation and cleanup of a camera just before\n",
    "# and just after the acquisition of images. Image retrieval and conversion,\n",
    "# grabbing image data, and saving images are all covered as well.\n",
    "#\n",
    "# Once comfortable with Acquisition, we suggest checking out\n",
    "# AcquisitionMultipleCamera, NodeMapCallback, or SaveToAvi.\n",
    "# AcquisitionMultipleCamera demonstrates simultaneously acquiring images from\n",
    "# a number of cameras, NodeMapCallback serves as a good introduction to\n",
    "# programming with callbacks and events, and SaveToAvi exhibits video creation.\n",
    "\n",
    "NUM_IMAGES = 10  # number of images to grab\n",
    "# insert the output of fisheye calibration step\n",
    "Img_DIM=(800, 800)\n",
    "dim1=(800, 800)\n",
    "dim2=(800, 800)\n",
    "dim3=(800, 800)\n",
    "balance = 1.0\n",
    "K=np.array([[351.6318033232932, 0.0, 450.4607527123814], [0.0, 351.7439651791754, 391.2576486450391], [0.0, 0.0, 1.0]])\n",
    "D=np.array([[-0.170592708935433], [0.5324235902617314], [-1.5452235955907878], [1.4793950832426657]])\n",
    "\n",
    "\n",
    "ROI_y = 850\n",
    "ROI_x = 550\n",
    "ROI_height = 800\n",
    "ROI_width = 800\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def acquire_images(cam, nodemap, nodemap_tldevice):\n",
    "    \"\"\"\n",
    "    This function acquires and saves 10 images from a device.\n",
    "\n",
    "    :param cam: Camera to acquire images from.\n",
    "    :param nodemap: Device nodemap.\n",
    "    :param nodemap_tldevice: Transport layer device nodemap.\n",
    "    :type cam: CameraPtr\n",
    "    :type nodemap: INodeMap\n",
    "    :type nodemap_tldevice: INodeMap\n",
    "    :return: True if successful, False otherwise.\n",
    "    :rtype: bool\n",
    "    \"\"\"\n",
    "\n",
    "    print('*** IMAGE ACQUISITION ***\\n')\n",
    "    try:\n",
    "        result = True\n",
    "        use_brect = True\n",
    "\n",
    "        # Set acquisition mode to continuous\n",
    "        #\n",
    "        #  *** NOTES ***\n",
    "        #  Because the example acquires and saves 10 images, setting acquisition\n",
    "        #  mode to continuous lets the example finish. If set to single frame\n",
    "        #  or multiframe (at a lower number of images), the example would just\n",
    "        #  hang. This would happen because the example has been written to\n",
    "        #  acquire 10 images while the camera would have been programmed to\n",
    "        #  retrieve less than that.\n",
    "        #\n",
    "        #  Setting the value of an enumeration node is slightly more complicated\n",
    "        #  than other node types. Two nodes must be retrieved: first, the\n",
    "        #  enumeration node is retrieved from the nodemap; and second, the entry\n",
    "        #  node is retrieved from the enumeration node. The integer value of the\n",
    "        #  entry node is then set as the new value of the enumeration node.\n",
    "        #\n",
    "        #  Notice that both the enumeration and the entry nodes are checked for\n",
    "        #  availability and readability/writability. Enumeration nodes are\n",
    "        #  generally readable and writable whereas their entry nodes are only\n",
    "        #  ever readable.\n",
    "        #\n",
    "        #  Retrieve enumeration node from nodemap\n",
    "\n",
    "        # In order to access the node entries, they have to be casted to a pointer type (CEnumerationPtr here)\n",
    "        node_acquisition_mode = spin.CEnumerationPtr(nodemap.GetNode('AcquisitionMode'))\n",
    "        if not spin.IsAvailable(node_acquisition_mode) or not spin.IsWritable(node_acquisition_mode):\n",
    "            print('Unable to set acquisition mode to continuous (enum retrieval). Aborting...')\n",
    "            return False\n",
    "\n",
    "        # Retrieve entry node from enumeration node\n",
    "        node_acquisition_mode_continuous = node_acquisition_mode.GetEntryByName('Continuous')\n",
    "        if not spin.IsAvailable(node_acquisition_mode_continuous) or not spin.IsReadable(node_acquisition_mode_continuous):\n",
    "            print('Unable to set acquisition mode to continuous (entry retrieval). Aborting...')\n",
    "            return False\n",
    "\n",
    "        # Retrieve integer value from entry node\n",
    "        acquisition_mode_continuous = node_acquisition_mode_continuous.GetValue()\n",
    "\n",
    "        # Set integer value from entry node as new value of enumeration node\n",
    "        node_acquisition_mode.SetIntValue(acquisition_mode_continuous)\n",
    "\n",
    "        print('Acquisition mode set to continuous...')\n",
    "\n",
    "        #  Begin acquiring images\n",
    "        #\n",
    "        #  *** NOTES ***\n",
    "        #  What happens when the camera begins acquiring images depends on the\n",
    "        #  acquisition mode. Single frame captures only a single image, multi\n",
    "        #  frame catures a set number of images, and continuous captures a\n",
    "        #  continuous stream of images. Because the example calls for the\n",
    "        #  retrieval of 10 images, continuous mode has been set.\n",
    "        #\n",
    "        #  *** LATER ***\n",
    "        #  Image acquisition must be ended when no more images are needed.\n",
    "        #cam.PixelFormat.SetValue(spin.PixelFormat_BGR8)\n",
    "        cam.BeginAcquisition()\n",
    "\n",
    "        print('Acquiring images...')\n",
    "\n",
    "        #  Retrieve device serial number for filename\n",
    "        #\n",
    "        #  *** NOTES ***\n",
    "        #  The device serial number is retrieved in order to keep cameras from\n",
    "        #  overwriting one another. Grabbing image IDs could also accomplish\n",
    "        #  this.\n",
    "        device_serial_number = ''\n",
    "        node_device_serial_number = spin.CStringPtr(nodemap_tldevice.GetNode('DeviceSerialNumber'))\n",
    "        if spin.IsAvailable(node_device_serial_number) and spin.IsReadable(node_device_serial_number):\n",
    "            device_serial_number = node_device_serial_number.GetValue()\n",
    "            print('Device serial number retrieved as %s...' % device_serial_number)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "        ## acquire parameters for undistortion\n",
    "        \n",
    "        \n",
    "        #dim1 = Img_DIM.shape[:2][::-1]  #dim1 is the dimension of input image to un-distort\n",
    "    \n",
    "        # assert dim1[0]/dim1[1] == DIM[0]/DIM[1], \"Image to undistort needs to have same aspect ratio as the ones used in calibration\"\n",
    "    \n",
    "        #if not dim2:\n",
    "        #    dim2 = dim1\n",
    "        #if not dim3:\n",
    "        #    dim3 = dim1\n",
    "        \n",
    "        \n",
    "        scaled_K = K * dim1[0] / Img_DIM[0]  # The values of K is to scale with image dimension.\n",
    "        scaled_K[2][2] = 1.0  # Except that K[2][2] is always 1.0\n",
    "    \n",
    "        # This is how scaled_K, dim2 and balance are used to determine the final K used to un-distort image. OpenCV document failed to make this clear!\n",
    "        new_K = cv2.fisheye.estimateNewCameraMatrixForUndistortRectify(scaled_K, D, dim2, np.eye(3), balance=balance)\n",
    "        map1, map2 = cv2.fisheye.initUndistortRectifyMap(scaled_K, D, np.eye(3), new_K, dim3, cv2.CV_16SC2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Retrieve, convert, and save images\n",
    "        with mp_hands.Hands(\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as hands:\n",
    "            ## this is for termianting the while loop\n",
    "            try:\n",
    "                \n",
    "                ## for gesture recognition\n",
    "                keypoint_classifier = KeyPointClassifier()\n",
    "\n",
    "                point_history_classifier = PointHistoryClassifier()\n",
    "\n",
    "                # Read labels ###########################################################\n",
    "                with open('model/keypoint_classifier/keypoint_classifier_label.csv',\n",
    "                          encoding='utf-8-sig') as f:\n",
    "                    keypoint_classifier_labels = csv.reader(f)\n",
    "                    keypoint_classifier_labels = [\n",
    "                        row[0] for row in keypoint_classifier_labels\n",
    "                    ]\n",
    "                with open(\n",
    "                        'model/point_history_classifier/point_history_classifier_label.csv',\n",
    "                        encoding='utf-8-sig') as f:\n",
    "                    point_history_classifier_labels = csv.reader(f)\n",
    "                    point_history_classifier_labels = [\n",
    "                        row[0] for row in point_history_classifier_labels\n",
    "                    ]\n",
    "\n",
    "                # FPS Measurement ########################################################\n",
    "                cvFpsCalc = CvFpsCalc(buffer_len=10)\n",
    "\n",
    "                # Coordinate history #################################################################\n",
    "                history_length = 16\n",
    "                point_history = deque(maxlen=history_length)\n",
    "\n",
    "                # Finger gesture history ################################################\n",
    "                finger_gesture_history = deque(maxlen=history_length)\n",
    "\n",
    "                #  ########################################################################\n",
    "                \n",
    "                mode = 0\n",
    "                \n",
    "                \n",
    "                while True:\n",
    "                    \n",
    "                    \n",
    "                    try:\n",
    "                        fps = cvFpsCalc.get()\n",
    "                        # Process Key (ESC: end) #################################################\n",
    "                        key = cv2.waitKey(1)\n",
    "                        if key == 27:  # ESC\n",
    "                            break\n",
    "                        number, mode = select_mode(key, mode)\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        ## unity communication\n",
    "                        ## I sam not sure of the position of this function yet...\n",
    "                        # need to include multiple hand tracking here, maybe via id?\n",
    "                        message = socket.recv()\n",
    "                        print(\"Received request: %s\" % message)\n",
    "                        unity_output = \"-1\" # when no gesture is detected -1 will be returned\n",
    "                        \n",
    "                        stringMessage = message.decode(\"utf-8\")\n",
    "                        stringMessage = stringMessage.strip()\n",
    "                        if stringMessage == \"END\":\n",
    "                            print(\"Should END\")\n",
    "                            output_byte = str.encode(\"END\")\n",
    "                            socket.send(b\"%s\" % output_byte)\n",
    "                            break\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        #  Retrieve next received image\n",
    "                        #\n",
    "                        #  *** NOTES ***\n",
    "                        #  Capturing an image houses images on the camera buffer. Trying\n",
    "                        #  to capture an image that does not exist will hang the camera.\n",
    "                        #\n",
    "                        #  *** LATER ***\n",
    "                        #  Once an image from the buffer is saved and/or no longer\n",
    "                        #  needed, the image must be released in order to keep the\n",
    "                        #  buffer from filling up.\n",
    "                        image_result = cam.GetNextImage()\n",
    "                        \n",
    "                        \n",
    "                                               \n",
    "                    \n",
    "                        #  Ensure image completion\n",
    "                        #\n",
    "                        #  *** NOTES ***\n",
    "                        #  Images can easily be checked for completion. This should be\n",
    "                        #  done whenever a complete image is expected or required.\n",
    "                        #  Further, check image status for a little more insight into\n",
    "                        #  why an image is incomplete.\n",
    "                        if image_result.IsIncomplete():\n",
    "                            print('Image incomplete with image status %d ...' % image_result.GetImageStatus())\n",
    "\n",
    "                        else:\n",
    "    \n",
    "                            #  Print image information; height and width recorded in pixels\n",
    "                            #\n",
    "                            #  *** NOTES ***\n",
    "                            #  Images have quite a bit of available metadata including\n",
    "                            #  things such as CRC, image status, and offset values, to\n",
    "                            #  name a few.\n",
    "                            ## This is 2048x2048 so we need to crop it to the ROI from the lense\n",
    "                            width = image_result.GetWidth()\n",
    "                            height = image_result.GetHeight()\n",
    "                            #print('Grabbed Image %d, width = %d, height = %d' % (i, width, height))\n",
    "\n",
    "                            #  Convert image to Pixel fomrat bgr\n",
    "                            #\n",
    "                            #  *** NOTES ***\n",
    "                            #  Images can be converted between pixel formats by using\n",
    "                            #  the appropriate enumeration value. Unlike the original\n",
    "                            #  image, the converted one does not need to be released as\n",
    "                            #  it does not affect the camera buffer.\n",
    "                            #\n",
    "                            #  When converting images, color processing algorithm is an\n",
    "                            #  optional parameter.\n",
    "                        \n",
    "                            ## This converts it to GreyScale\n",
    "                            #image_converted = image_result.Convert(spin.PixelFormat_Mono8, spin.HQ_LINEAR)\n",
    "                            ## This converts it to RGB\n",
    "                            image_converted = image_result.Convert(spin.PixelFormat_BGR8)\n",
    "                            rgb_array = image_converted.GetData()\n",
    "                            rgb_array = rgb_array.reshape(height, width, 3)\n",
    "                            \n",
    "                            \n",
    "                            ## process mediapipe on image\n",
    "                            \n",
    "                            ## for mirrored image comment this in\n",
    "                            image_rgb = cv2.flip(rgb_array, 1)\n",
    "                            ## for un-mirrored image\n",
    "                            #image_rgb = rgb_array #cv2.flip(rgb_array, 1)\n",
    "                            \n",
    "                            \n",
    "                            ## **** Resizing / Croping *****\n",
    "                            \n",
    "                            ## RESIZING the image since it would be 2048x2048 otherwise (kind of too big for the window)\n",
    "                            #image_rgb = cv2.resize(image_rgb, (800, 800))\n",
    "                            \n",
    "                            ## CROPPPING the region of the lense (should be around 800 to fit with the setup so far...)\n",
    "                            # array_cropped = image_rgb[ROI_y:(ROI_y + ROI_height), ROI_x:(ROI_x + ROI_width)]\n",
    "                            # image_rgb = array_cropped.copy() # needed to get the correct data format for further processing\n",
    "                            \n",
    "                            \n",
    "                            \n",
    "                            \n",
    "                            ## **** un-distort image\n",
    "                            \n",
    "                            #undistorted_img = cv2.remap(image_rgb, map1, map2, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)\n",
    "                            \n",
    "                            #image_rgb = cv2.cvtColor(undistorted_img, cv2.COLOR_BGR2RGB)\n",
    "                            \n",
    "                            # image needs to be sized further down for mediapipe to run fast\n",
    "                            image_rgb = cv2.resize(image_rgb, (400, 400))\n",
    "                            \n",
    "                            ## **** Mediapipe hand detection ****\n",
    "                            image_rgb.flags.writeable = False\n",
    "                            results = hands.process(image_rgb)\n",
    "                            image_rgb.flags.writeable = True\n",
    "                            \n",
    "                            debug_image = copy.deepcopy(image_rgb)\n",
    "                            \n",
    "                            # Draw the hand annotations on the image.\n",
    "                            if results.multi_hand_landmarks:\n",
    "                                \n",
    "                                # need to overwrite unity_output so that it will not start with -1\n",
    "                                unity_output = \"\"\n",
    "                                \n",
    "                                for hand_landmarks, handedness in zip(results.multi_hand_landmarks,\n",
    "                                                  results.multi_handedness):\n",
    "                                    mp_drawing.draw_landmarks(image_rgb, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                                    \n",
    "                                    ## gesture recognition\n",
    "                                    \n",
    "                                    # Bounding box calculation\n",
    "                                    brect = calc_bounding_rect(debug_image, hand_landmarks)\n",
    "                                    # Landmark calculation\n",
    "                                    landmark_list = calc_landmark_list(debug_image, hand_landmarks)\n",
    "\n",
    "                                    # Conversion to relative coordinates / normalized coordinates\n",
    "                                    pre_processed_landmark_list = pre_process_landmark(landmark_list)\n",
    "                                    pre_processed_point_history_list = pre_process_point_history(\n",
    "                                        debug_image, point_history)\n",
    "                                    # Write to the dataset file\n",
    "                                    logging_csv(number, mode, pre_processed_landmark_list,\n",
    "                                                pre_processed_point_history_list)\n",
    "\n",
    "                                    # Hand sign classification\n",
    "                                    hand_sign_id = keypoint_classifier(pre_processed_landmark_list)\n",
    "                                    if hand_sign_id == 2:  # Point gesture\n",
    "                                        point_history.append(landmark_list[8])\n",
    "                                    else:\n",
    "                                        point_history.append([0, 0])\n",
    "\n",
    "                                    # Finger gesture classification\n",
    "                                    finger_gesture_id = 0\n",
    "                                    point_history_len = len(pre_processed_point_history_list)\n",
    "                                    if point_history_len == (history_length * 2):\n",
    "                                        finger_gesture_id = point_history_classifier(\n",
    "                                            pre_processed_point_history_list)\n",
    "\n",
    "                                    # Calculates the gesture IDs in the latest detection\n",
    "                                    finger_gesture_history.append(finger_gesture_id)\n",
    "                                    most_common_fg_id = Counter(\n",
    "                                        finger_gesture_history).most_common()\n",
    "\n",
    "                                    # Drawing part\n",
    "                                    debug_image = draw_bounding_rect(use_brect, debug_image, brect)\n",
    "                                    debug_image = draw_landmarks(debug_image, landmark_list)\n",
    "                                    debug_image = draw_info_text(\n",
    "                                        debug_image,\n",
    "                                        brect,\n",
    "                                        handedness,\n",
    "                                        keypoint_classifier_labels[hand_sign_id],\n",
    "                                        point_history_classifier_labels[most_common_fg_id[0][0]],\n",
    "                                    )\n",
    "                                    \n",
    "                                    \n",
    "                                    ## with this only the last detected hand will be displayed but we want all\n",
    "                                    \n",
    "                                    # writing hand_sign to unity output\n",
    "                                    unity_output = unity_output + str(hand_sign_id)\n",
    "                                    \n",
    "                                    ## Landmark calcualtion with 3 coordinates\n",
    "                                    hand_landmarks_list = get_hand_landmarks_list(debug_image, hand_landmarks)\n",
    "                                    ## convert hand_landmarks_list to string\n",
    "                                    string_list = \";\".join(str(x) for x in hand_landmarks_list)\n",
    "                                    #print(\"normalized hand_landmarks: \" + string_list)\n",
    "                                    \n",
    "                                    # add an \"h\" for showing that one hand is finished\n",
    "                                    unity_output = unity_output + \":\" + string_list + \"h\"\n",
    "                                    \n",
    "                                    \n",
    "                                    \n",
    "                                    \n",
    "                                    \n",
    "                                    \n",
    "                            \n",
    "                            debug_image = draw_point_history(debug_image, point_history)\n",
    "                            debug_image = draw_info(debug_image, fps, mode, number)\n",
    "\n",
    "                            # Screen reflection #############################################################\n",
    "                            cv2.imshow('Hand Gesture Recognition', debug_image)\n",
    "                            \n",
    "                            cv2.imshow('MediaPipe Hands', image_rgb)\n",
    "                            if cv2.waitKey(5) & 0xFF == 27:\n",
    "                                break\n",
    "                                \n",
    "                            image_result.Release()\n",
    "                            \n",
    "                        \n",
    "                        \n",
    "                        ## write gesture output to send to unity\n",
    "                        output_byte = str.encode(unity_output)\n",
    "\n",
    "                        #  Send reply back to client\n",
    "                        #  In the real world usage, after you finish your work, send your output here\n",
    "                        socket.send(b\"%s\" % output_byte)\n",
    "                        \n",
    "                        \n",
    "                                    \n",
    "\n",
    "                    except spin.SpinnakerException as ex:\n",
    "                        print('Error: %s' % ex)\n",
    "                        return False\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                print('While loop interrupted')\n",
    "                cv2.destroyAllWindows()\n",
    "                \n",
    "                \n",
    "                \n",
    "        #  End acquisition\n",
    "        #\n",
    "        #  *** NOTES ***\n",
    "        #  Ending acquisition appropriately helps ensure that devices clean up\n",
    "        #  properly and do not need to be power-cycled to maintain integrity.\n",
    "        cam.EndAcquisition()\n",
    "    \n",
    "    except spin.SpinnakerException as ex:\n",
    "        print('Error: %s' % ex)\n",
    "        return False\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## converting hand_landmarks to sendable vector3 string list?\n",
    "## returns a list of all handmarks and their 3 coordinates (normalized)\n",
    "def get_hand_landmarks_list(image, landmarks):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_point = []\n",
    "\n",
    "    # Keypoint\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = landmark.x\n",
    "        landmark_y = landmark.y\n",
    "        landmark_z = landmark.z\n",
    "        #landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        #landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "        #landmark_z = landmark.z\n",
    "\n",
    "        \n",
    "        ## need the brackets for this function\n",
    "        landmark_point.append([landmark_x, landmark_y, landmark_z])\n",
    "\n",
    "    return landmark_point\n",
    "\n",
    "\n",
    "\n",
    "## gesture recognition functions\n",
    "\n",
    "def select_mode(key, mode):\n",
    "    number = -1\n",
    "    if 48 <= key <= 57:  # 0 ~ 9\n",
    "        number = key - 48\n",
    "    if key == 110:  # n\n",
    "        mode = 0\n",
    "    if key == 107:  # k\n",
    "        print(\"Changed path to writing\")\n",
    "        mode = 1\n",
    "    if key == 104:  # h\n",
    "        mode = 2\n",
    "    return number, mode\n",
    "\n",
    "def calc_bounding_rect(image, landmarks):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_array = np.empty((0, 2), int)\n",
    "\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "\n",
    "        landmark_point = [np.array((landmark_x, landmark_y))]\n",
    "\n",
    "        landmark_array = np.append(landmark_array, landmark_point, axis=0)\n",
    "\n",
    "    x, y, w, h = cv2.boundingRect(landmark_array)\n",
    "\n",
    "    return [x, y, x + w, y + h]\n",
    "\n",
    "\n",
    "def calc_landmark_list(image, landmarks):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_point = []\n",
    "\n",
    "    # Keypoint\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "        # landmark_z = landmark.z\n",
    "\n",
    "        landmark_point.append([landmark_x, landmark_y])\n",
    "\n",
    "    return landmark_point\n",
    "\n",
    "\n",
    "def pre_process_landmark(landmark_list):\n",
    "    temp_landmark_list = copy.deepcopy(landmark_list)\n",
    "\n",
    "    # Convert to relative coordinates\n",
    "    base_x, base_y = 0, 0\n",
    "    for index, landmark_point in enumerate(temp_landmark_list):\n",
    "        if index == 0:\n",
    "            base_x, base_y = landmark_point[0], landmark_point[1]\n",
    "\n",
    "        temp_landmark_list[index][0] = temp_landmark_list[index][0] - base_x\n",
    "        temp_landmark_list[index][1] = temp_landmark_list[index][1] - base_y\n",
    "\n",
    "    # Convert to a one-dimensional list\n",
    "    temp_landmark_list = list(\n",
    "        itertools.chain.from_iterable(temp_landmark_list))\n",
    "\n",
    "    # Normalization\n",
    "    max_value = max(list(map(abs, temp_landmark_list)))\n",
    "\n",
    "    def normalize_(n):\n",
    "        return n / max_value\n",
    "\n",
    "    temp_landmark_list = list(map(normalize_, temp_landmark_list))\n",
    "\n",
    "    return temp_landmark_list\n",
    "\n",
    "\n",
    "def pre_process_point_history(image, point_history):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    temp_point_history = copy.deepcopy(point_history)\n",
    "\n",
    "    # Convert to relative coordinates\n",
    "    base_x, base_y = 0, 0\n",
    "    for index, point in enumerate(temp_point_history):\n",
    "        if index == 0:\n",
    "            base_x, base_y = point[0], point[1]\n",
    "\n",
    "        temp_point_history[index][0] = (temp_point_history[index][0] -\n",
    "                                        base_x) / image_width\n",
    "        temp_point_history[index][1] = (temp_point_history[index][1] -\n",
    "                                        base_y) / image_height\n",
    "\n",
    "    # Convert to a one-dimensional list\n",
    "    temp_point_history = list(\n",
    "        itertools.chain.from_iterable(temp_point_history))\n",
    "\n",
    "    return temp_point_history\n",
    "\n",
    "\n",
    "def logging_csv(number, mode, landmark_list, point_history_list):\n",
    "    if mode == 0:\n",
    "        pass\n",
    "    if mode == 1 and (0 <= number <= 9):\n",
    "        csv_path = 'model/keypoint_classifier/keypointOmni.csv'\n",
    "        with open(csv_path, 'a', newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([number, *landmark_list])\n",
    "    if mode == 2 and (0 <= number <= 9):\n",
    "        csv_path = 'model/point_history_classifier/point_history.csv'\n",
    "        with open(csv_path, 'a', newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([number, *point_history_list])\n",
    "    return\n",
    "\n",
    "def draw_landmarks(image, landmark_point):\n",
    "    if len(landmark_point) > 0:\n",
    "        # Thumb\n",
    "        cv2.line(image, tuple(landmark_point[2]), tuple(landmark_point[3]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv2.line(image, tuple(landmark_point[2]), tuple(landmark_point[3]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv2.line(image, tuple(landmark_point[3]), tuple(landmark_point[4]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv2.line(image, tuple(landmark_point[3]), tuple(landmark_point[4]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "        # Index finger\n",
    "        cv2.line(image, tuple(landmark_point[5]), tuple(landmark_point[6]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv2.line(image, tuple(landmark_point[5]), tuple(landmark_point[6]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv2.line(image, tuple(landmark_point[6]), tuple(landmark_point[7]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv2.line(image, tuple(landmark_point[6]), tuple(landmark_point[7]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv2.line(image, tuple(landmark_point[7]), tuple(landmark_point[8]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv2.line(image, tuple(landmark_point[7]), tuple(landmark_point[8]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "        # Middle finger\n",
    "        cv2.line(image, tuple(landmark_point[9]), tuple(landmark_point[10]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv2.line(image, tuple(landmark_point[9]), tuple(landmark_point[10]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv2.line(image, tuple(landmark_point[10]), tuple(landmark_point[11]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv2.line(image, tuple(landmark_point[10]), tuple(landmark_point[11]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv2.line(image, tuple(landmark_point[11]), tuple(landmark_point[12]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv2.line(image, tuple(landmark_point[11]), tuple(landmark_point[12]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "        # Ring finger\n",
    "        cv2.line(image, tuple(landmark_point[13]), tuple(landmark_point[14]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv2.line(image, tuple(landmark_point[13]), tuple(landmark_point[14]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv2.line(image, tuple(landmark_point[14]), tuple(landmark_point[15]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv2.line(image, tuple(landmark_point[14]), tuple(landmark_point[15]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv2.line(image, tuple(landmark_point[15]), tuple(landmark_point[16]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv2.line(image, tuple(landmark_point[15]), tuple(landmark_point[16]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "        # Little finger\n",
    "        cv2.line(image, tuple(landmark_point[17]), tuple(landmark_point[18]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv2.line(image, tuple(landmark_point[17]), tuple(landmark_point[18]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv2.line(image, tuple(landmark_point[18]), tuple(landmark_point[19]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv2.line(image, tuple(landmark_point[18]), tuple(landmark_point[19]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv2.line(image, tuple(landmark_point[19]), tuple(landmark_point[20]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv2.line(image, tuple(landmark_point[19]), tuple(landmark_point[20]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "        # Palm\n",
    "        cv2.line(image, tuple(landmark_point[0]), tuple(landmark_point[1]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv2.line(image, tuple(landmark_point[0]), tuple(landmark_point[1]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv2.line(image, tuple(landmark_point[1]), tuple(landmark_point[2]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv2.line(image, tuple(landmark_point[1]), tuple(landmark_point[2]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv2.line(image, tuple(landmark_point[2]), tuple(landmark_point[5]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv2.line(image, tuple(landmark_point[2]), tuple(landmark_point[5]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv2.line(image, tuple(landmark_point[5]), tuple(landmark_point[9]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv2.line(image, tuple(landmark_point[5]), tuple(landmark_point[9]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv2.line(image, tuple(landmark_point[9]), tuple(landmark_point[13]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv2.line(image, tuple(landmark_point[9]), tuple(landmark_point[13]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv2.line(image, tuple(landmark_point[13]), tuple(landmark_point[17]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv2.line(image, tuple(landmark_point[13]), tuple(landmark_point[17]),\n",
    "                (255, 255, 255), 2)\n",
    "        cv2.line(image, tuple(landmark_point[17]), tuple(landmark_point[0]),\n",
    "                (0, 0, 0), 6)\n",
    "        cv2.line(image, tuple(landmark_point[17]), tuple(landmark_point[0]),\n",
    "                (255, 255, 255), 2)\n",
    "\n",
    "    # Key Points\n",
    "    for index, landmark in enumerate(landmark_point):\n",
    "        if index == 0:  # 手首1\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 1:  # 手首2\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 2:  # 親指：付け根\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 3:  # 親指：第1関節\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 4:  # 親指：指先\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)\n",
    "        if index == 5:  # 人差指：付け根\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 6:  # 人差指：第2関節\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 7:  # 人差指：第1関節\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 8:  # 人差指：指先\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)\n",
    "        if index == 9:  # 中指：付け根\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 10:  # 中指：第2関節\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 11:  # 中指：第1関節\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 12:  # 中指：指先\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)\n",
    "        if index == 13:  # 薬指：付け根\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 14:  # 薬指：第2関節\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 15:  # 薬指：第1関節\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 16:  # 薬指：指先\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)\n",
    "        if index == 17:  # 小指：付け根\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 18:  # 小指：第2関節\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 19:  # 小指：第1関節\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 5, (0, 0, 0), 1)\n",
    "        if index == 20:  # 小指：指先\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 8, (255, 255, 255),\n",
    "                      -1)\n",
    "            cv2.circle(image, (landmark[0], landmark[1]), 8, (0, 0, 0), 1)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_bounding_rect(use_brect, image, brect):\n",
    "    if use_brect:\n",
    "        # Outer rectangle\n",
    "        cv2.rectangle(image, (brect[0], brect[1]), (brect[2], brect[3]),\n",
    "                     (0, 0, 0), 1)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_info_text(image, brect, handedness, hand_sign_text,\n",
    "                   finger_gesture_text):\n",
    "    cv2.rectangle(image, (brect[0], brect[1]), (brect[2], brect[1] - 22),\n",
    "                 (0, 0, 0), -1)\n",
    "\n",
    "    info_text = handedness.classification[0].label[0:]\n",
    "    if hand_sign_text != \"\":\n",
    "        info_text = info_text + ':' + hand_sign_text\n",
    "    cv2.putText(image, info_text, (brect[0] + 5, brect[1] - 4),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    if finger_gesture_text != \"\":\n",
    "        cv2.putText(image, \"Finger Gesture:\" + finger_gesture_text, (10, 60),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 0), 4, cv2.LINE_AA)\n",
    "        cv2.putText(image, \"Finger Gesture:\" + finger_gesture_text, (10, 60),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2,\n",
    "                   cv2.LINE_AA)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_point_history(image, point_history):\n",
    "    for index, point in enumerate(point_history):\n",
    "        if point[0] != 0 and point[1] != 0:\n",
    "            cv2.circle(image, (point[0], point[1]), 1 + int(index / 2),\n",
    "                      (152, 251, 152), 2)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_info(image, fps, mode, number):\n",
    "    cv2.putText(image, \"FPS:\" + str(fps), (10, 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "               1.0, (0, 0, 0), 4, cv2.LINE_AA)\n",
    "    cv2.putText(image, \"FPS:\" + str(fps), (10, 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "               1.0, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    mode_string = ['Logging Key Point', 'Logging Point History']\n",
    "    if 1 <= mode <= 2:\n",
    "        cv2.putText(image, \"MODE:\" + mode_string[mode - 1], (10, 90),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1,\n",
    "                   cv2.LINE_AA)\n",
    "        if 0 <= number <= 9:\n",
    "            cv2.putText(image, \"NUM:\" + str(number), (10, 110),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1,\n",
    "                       cv2.LINE_AA)\n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def print_device_info(nodemap):\n",
    "    \"\"\"\n",
    "    This function prints the device information of the camera from the transport\n",
    "    layer; please see NodeMapInfo example for more in-depth comments on printing\n",
    "    device information from the nodemap.\n",
    "\n",
    "    :param nodemap: Transport layer device nodemap.\n",
    "    :type nodemap: INodeMap\n",
    "    :returns: True if successful, False otherwise.\n",
    "    :rtype: bool\n",
    "    \"\"\"\n",
    "\n",
    "    print('*** DEVICE INFORMATION ***\\n')\n",
    "\n",
    "    try:\n",
    "        result = True\n",
    "        node_device_information = spin.CCategoryPtr(nodemap.GetNode('DeviceInformation'))\n",
    "\n",
    "        if spin.IsAvailable(node_device_information) and spin.IsReadable(node_device_information):\n",
    "            features = node_device_information.GetFeatures()\n",
    "            for feature in features:\n",
    "                node_feature = spin.CValuePtr(feature)\n",
    "                print('%s: %s' % (node_feature.GetName(),\n",
    "                                  node_feature.ToString() if spin.IsReadable(node_feature) else 'Node not readable'))\n",
    "\n",
    "        else:\n",
    "            print('Device control information not available.')\n",
    "\n",
    "    except spin.SpinnakerException as ex:\n",
    "        print('Error: %s' % ex)\n",
    "        return False\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_single_camera(cam):\n",
    "    \"\"\"\n",
    "    This function acts as the body of the example; please see NodeMapInfo example\n",
    "    for more in-depth comments on setting up cameras.\n",
    "\n",
    "    :param cam: Camera to run on.\n",
    "    :type cam: CameraPtr\n",
    "    :return: True if successful, False otherwise.\n",
    "    :rtype: bool\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = True\n",
    "\n",
    "        # Retrieve TL device nodemap and print device information\n",
    "        nodemap_tldevice = cam.GetTLDeviceNodeMap()\n",
    "\n",
    "        result &= print_device_info(nodemap_tldevice)\n",
    "\n",
    "        # Initialize camera\n",
    "        cam.Init()\n",
    "\n",
    "        # Retrieve GenICam nodemap\n",
    "        nodemap = cam.GetNodeMap()\n",
    "\n",
    "        # Acquire images\n",
    "        result &= acquire_images(cam, nodemap, nodemap_tldevice)\n",
    "\n",
    "        # Deinitialize camera\n",
    "        cam.DeInit()\n",
    "\n",
    "    except spin.SpinnakerException as ex:\n",
    "        print('Error: %s' % ex)\n",
    "        result = False\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Example entry point; please see Enumeration example for more in-depth\n",
    "    comments on preparing and cleaning up the system.\n",
    "\n",
    "    :return: True if successful, False otherwise.\n",
    "    :rtype: bool\n",
    "    \"\"\"\n",
    "\n",
    "    # Since this application saves images in the current folder\n",
    "    # we must ensure that we have permission to write to this folder.\n",
    "    # If we do not have permission, fail right away.\n",
    "    try:\n",
    "        test_file = open('test.txt', 'w+')\n",
    "    except IOError:\n",
    "        print('Unable to write to current directory. Please check permissions.')\n",
    "        input('Press Enter to exit...')\n",
    "        return False\n",
    "\n",
    "    test_file.close()\n",
    "    os.remove(test_file.name)\n",
    "\n",
    "    result = True\n",
    "\n",
    "    # Retrieve singleton reference to system object\n",
    "    system = spin.System.GetInstance()\n",
    "\n",
    "    # Get current library version\n",
    "    version = system.GetLibraryVersion()\n",
    "    print('Library version: %d.%d.%d.%d' % (version.major, version.minor, version.type, version.build))\n",
    "\n",
    "    # Retrieve list of cameras from the system\n",
    "    cam_list = system.GetCameras()\n",
    "\n",
    "    num_cameras = cam_list.GetSize()\n",
    "\n",
    "    print('Number of cameras detected: %d' % num_cameras)\n",
    "\n",
    "    # Finish if there are no cameras\n",
    "    if num_cameras == 0:\n",
    "\n",
    "        # Clear camera list before releasing system\n",
    "        cam_list.Clear()\n",
    "\n",
    "        # Release system instance\n",
    "        system.ReleaseInstance()\n",
    "\n",
    "        print('Not enough cameras!')\n",
    "        input('Done! Press Enter to exit...')\n",
    "        return False\n",
    "\n",
    "    # Run example on each camera\n",
    "    for i, cam in enumerate(cam_list):\n",
    "\n",
    "        print('Running example for camera %d...' % i)\n",
    "\n",
    "        result &= run_single_camera(cam)\n",
    "        print('Camera %d example complete... \\n' % i)\n",
    "\n",
    "    # Release reference to camera\n",
    "    # NOTE: Unlike the C++ examples, we cannot rely on pointer objects being automatically\n",
    "    # cleaned up when going out of scope.\n",
    "    # The usage of del is preferred to assigning the variable to None.\n",
    "    del cam\n",
    "\n",
    "    # Clear camera list before releasing system\n",
    "    cam_list.Clear()\n",
    "\n",
    "    # Release system instance\n",
    "    system.ReleaseInstance()\n",
    "\n",
    "    input('Done! Press Enter to exit...')\n",
    "    cv2.destroyAllWindows()\n",
    "    return result\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if main():\n",
    "        sys.exit(0)\n",
    "    else:\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
